{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7f38b2",
   "metadata": {},
   "source": [
    "# AWS SageMaker Model Store: Time Series Demand Forecasting\n",
    "\n",
    "This notebook creates a model store for the time series forecasting models trained in `Modeling.ipynb`.\n",
    "\n",
    "It demonstrates:\n",
    "1. **Model Package Group** - Container for versioned models\n",
    "2. **Model Packages** - Individual model versions with inference specifications\n",
    "3. **Model Cards** - Metadata and documentation for each model\n",
    "4. **Model Registry** - Track trained models across versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ade524",
   "metadata": {},
   "source": [
    "## Setup & Initialize SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5671a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "SageMaker Role: arn:aws:iam::681195727402:role/LabRole\n",
      "Default S3 Bucket: sagemaker-us-east-1-681195727402\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"Default S3 Bucket: {bucket}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f981d8c8",
   "metadata": {},
   "source": [
    "## Part 1: Load & Serialize Trained Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "278db9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (121, 2)\n",
      "Date range: 2014-01-01 00:00:00 to 2024-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load the data and re-train models (or load from disk if available)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df_agg = df.groupby('timestamp')['value'].sum().reset_index()\n",
    "df_agg.columns = ['ds', 'y']\n",
    "df_agg = df_agg.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "print(f\"Data shape: {df_agg.shape}\")\n",
    "print(f\"Date range: {df_agg['ds'].min()} to {df_agg['ds'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16edb880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineered data shape: (109, 16)\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering function\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['month']         = df['ds'].dt.month\n",
    "    df['quarter']       = df['ds'].dt.quarter\n",
    "    df['year']          = df['ds'].dt.year\n",
    "    df['month_sin']     = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos']     = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['trend']         = np.arange(len(df))\n",
    "\n",
    "    for lag in [1, 2, 3, 6, 12]:\n",
    "        df[f'lag_{lag}'] = df['y'].shift(lag)\n",
    "\n",
    "    df['rolling_mean_3']  = df['y'].shift(1).rolling(3).mean()\n",
    "    df['rolling_mean_12'] = df['y'].shift(1).rolling(12).mean()\n",
    "    df['rolling_std_3']   = df['y'].shift(1).rolling(3).std()\n",
    "\n",
    "    return df\n",
    "\n",
    "df_feat = create_features(df_agg)\n",
    "df_feat = df_feat.dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"Feature engineered data shape: {df_feat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e457946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 97, Test samples: 12\n",
      "Features: 14\n"
     ]
    }
   ],
   "source": [
    "# Train/Test split\n",
    "TEST_MONTHS = 12\n",
    "\n",
    "feature_cols = [c for c in df_feat.columns if c not in ['ds', 'y']]\n",
    "\n",
    "train = df_feat.iloc[:-TEST_MONTHS]\n",
    "test  = df_feat.iloc[-TEST_MONTHS:]\n",
    "\n",
    "X_train, y_train = train[feature_cols], train['y']\n",
    "X_test,  y_test  = test[feature_cols],  test['y']\n",
    "\n",
    "train_ts = df_agg.iloc[:-TEST_MONTHS]['y']\n",
    "test_ts  = df_agg.iloc[-TEST_MONTHS:]['y']\n",
    "\n",
    "print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "print(f\"Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0747da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Linear Regression trained\n",
      "‚úì Ridge Regression trained\n",
      "‚úì Random Forest trained\n",
      "‚úì XGBoost trained\n",
      "‚úì LightGBM trained\n",
      "‚úì ETS (Holt-Winters) trained\n",
      "‚úì SARIMA trained\n"
     ]
    }
   ],
   "source": [
    "# Train all models\n",
    "models_dict = {}\n",
    "results_list = []\n",
    "\n",
    "def evaluate(name, y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((np.array(y_true) - np.array(y_pred)) / np.array(y_true))) * 100\n",
    "    return {'Model': name, 'MAE': mae, 'RMSE': rmse, 'R2': r2, 'MAPE': mape}\n",
    "\n",
    "# 1. Linear Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc  = scaler.transform(X_test)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_sc, y_train)\n",
    "lr_pred = lr.predict(X_test_sc)\n",
    "models_dict['Linear Regression'] = (lr, scaler, 'StandardScaler')\n",
    "results_list.append(evaluate(\"Linear Regression\", y_test, lr_pred))\n",
    "print(\"‚úì Linear Regression trained\")\n",
    "\n",
    "# 2. Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_sc, y_train)\n",
    "ridge_pred = ridge.predict(X_test_sc)\n",
    "models_dict['Ridge Regression'] = (ridge, scaler, 'StandardScaler')\n",
    "results_list.append(evaluate(\"Ridge Regression\", y_test, ridge_pred))\n",
    "print(\"‚úì Ridge Regression trained\")\n",
    "\n",
    "# 3. Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "models_dict['Random Forest'] = (rf, None, None)\n",
    "results_list.append(evaluate(\"Random Forest\", y_test, rf_pred))\n",
    "print(\"‚úì Random Forest trained\")\n",
    "\n",
    "# 4. XGBoost\n",
    "xgb = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, \n",
    "                   subsample=0.8, colsample_bytree=0.8, random_state=42, verbosity=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "models_dict['XGBoost'] = (xgb, None, None)\n",
    "results_list.append(evaluate(\"XGBoost\", y_test, xgb_pred))\n",
    "print(\"‚úì XGBoost trained\")\n",
    "\n",
    "# 5. LightGBM\n",
    "lgbm = LGBMRegressor(n_estimators=300, learning_rate=0.05, max_depth=4,\n",
    "                     subsample=0.8, colsample_bytree=0.8, random_state=42, verbose=-1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "lgbm_pred = lgbm.predict(X_test)\n",
    "models_dict['LightGBM'] = (lgbm, None, None)\n",
    "results_list.append(evaluate(\"LightGBM\", y_test, lgbm_pred))\n",
    "print(\"‚úì LightGBM trained\")\n",
    "\n",
    "# 6. ETS (Exponential Smoothing)\n",
    "ets_model = ExponentialSmoothing(train_ts, trend='add', seasonal='add', seasonal_periods=12).fit(optimized=True)\n",
    "ets_pred = ets_model.forecast(TEST_MONTHS)\n",
    "models_dict['ETS'] = (ets_model, None, None)\n",
    "results_list.append(evaluate(\"ETS (Holt-Winters)\", test_ts.values, ets_pred.values))\n",
    "print(\"‚úì ETS (Holt-Winters) trained\")\n",
    "\n",
    "# 7. SARIMA\n",
    "sarima_model = SARIMAX(train_ts, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12),\n",
    "                        enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
    "sarima_pred = sarima_model.forecast(TEST_MONTHS)\n",
    "models_dict['SARIMA'] = (sarima_model, None, None)\n",
    "results_list.append(evaluate(\"SARIMA(1,1,1)(1,1,1,12)\", test_ts, sarima_pred))\n",
    "print(\"‚úì SARIMA trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3171ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Performance (sorted by RMSE) ===\n",
      "                  Model           MAE          RMSE       R2     MAPE\n",
      "     ETS (Holt-Winters) 269600.946240 339687.886113 0.940767 2.622832\n",
      "SARIMA(1,1,1)(1,1,1,12) 292982.891776 441158.333879 0.900093 2.739047\n",
      "                XGBoost 344852.000000 446809.083481 0.897517 3.184616\n",
      "          Random Forest 323489.457083 478332.234626 0.882546 2.917507\n",
      "               LightGBM 321519.662545 491168.478068 0.876158 2.967178\n",
      "       Ridge Regression 432162.792811 513663.825094 0.864554 4.234959\n",
      "      Linear Regression 439440.987479 528703.889226 0.856507 4.302964\n",
      "\n",
      "üèÜ Best Model: ETS (Holt-Winters)\n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "results_df = pd.DataFrame(results_list).sort_values('RMSE').reset_index(drop=True)\n",
    "print(\"\\n=== Model Performance (sorted by RMSE) ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb60c2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All models saved to S3: s3://sagemaker-us-east-1-681195727402/timeseries-demand-forecasting/models/\n"
     ]
    }
   ],
   "source": [
    "# Save models to S3\n",
    "s3_prefix = 'timeseries-demand-forecasting/models'\n",
    "\n",
    "model_metadata = {}\n",
    "\n",
    "for model_name, (model_obj, scaler_obj, scaler_type) in models_dict.items():\n",
    "    # Serialize model\n",
    "    model_bytes = pickle.dumps(model_obj)\n",
    "    \n",
    "    # Save to S3\n",
    "    s3_key = f\"{s3_prefix}/{model_name.replace(' ', '_').replace('(', '').replace(')', '')}.pkl\"\n",
    "    s3_client.put_object(Bucket=bucket, Key=s3_key, Body=model_bytes)\n",
    "    \n",
    "    # Save scaler if exists\n",
    "    if scaler_obj is not None:\n",
    "        scaler_bytes = pickle.dumps(scaler_obj)\n",
    "        scaler_key = f\"{s3_prefix}/{model_name.replace(' ', '_').replace('(', '').replace(')', '')}_scaler.pkl\"\n",
    "        s3_client.put_object(Bucket=bucket, Key=scaler_key, Body=scaler_bytes)\n",
    "        model_metadata[model_name] = {\n",
    "            'model_s3_path': f\"s3://{bucket}/{s3_key}\",\n",
    "            'scaler_s3_path': f\"s3://{bucket}/{scaler_key}\",\n",
    "            'scaler_type': scaler_type\n",
    "        }\n",
    "    else:\n",
    "        model_metadata[model_name] = {\n",
    "            'model_s3_path': f\"s3://{bucket}/{s3_key}\",\n",
    "            'scaler_s3_path': None,\n",
    "            'scaler_type': None\n",
    "        }\n",
    "\n",
    "print(f\"‚úì All models saved to S3: s3://{bucket}/{s3_prefix}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104095cb",
   "metadata": {},
   "source": [
    "## Part 2: Create Model Package Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef0cb8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model Package Group 'timeseries-demand-forecasting' already exists.\n",
      "\n",
      "Model Package Group Status: Completed\n"
     ]
    }
   ],
   "source": [
    "# Create Model Package Group\n",
    "model_package_group_name = \"timeseries-demand-forecasting\"\n",
    "model_package_group_description = \"Time Series Demand Forecasting Models - NG Demand Forecasting\"\n",
    "\n",
    "try:\n",
    "    sm_client.create_model_package_group(\n",
    "        ModelPackageGroupName=model_package_group_name,\n",
    "        ModelPackageGroupDescription=model_package_group_description\n",
    "    )\n",
    "    print(f\"‚úì Model Package Group '{model_package_group_name}' created successfully.\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        print(f\"‚úì Model Package Group '{model_package_group_name}' already exists.\")\n",
    "    else:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Describe the group\n",
    "response = sm_client.describe_model_package_group(\n",
    "    ModelPackageGroupName=model_package_group_name\n",
    ")\n",
    "print(f\"\\nModel Package Group Status: {response['ModelPackageGroupStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f0188b",
   "metadata": {},
   "source": [
    "## Part 3: Create Model Packages for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ca3bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Could not retrieve SageMaker images: Unsupported sklearn version: None. You may need to upgrade your SDK version (pip install -U sagemaker) for newer sklearn versions. Supported sklearn version(s): 0.20.0, 0.23-1, 1.0-1, 1.2-1.\n",
      "‚úì Model Package created for Linear Regression (metadata-only)\n",
      "  ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/1\n",
      "‚úì Model Package created for Ridge Regression (metadata-only)\n",
      "  ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/2\n",
      "‚úì Model Package created for Random Forest (metadata-only)\n",
      "  ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/3\n",
      "‚úì Model Package created for XGBoost (metadata-only)\n",
      "  ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/4\n",
      "‚úì Model Package created for LightGBM (metadata-only)\n",
      "  ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/5\n",
      "‚úì Model Package created for ETS (metadata-only)\n",
      "  ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/6\n",
      "‚úì Model Package created for SARIMA (metadata-only)\n",
      "  ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/7\n"
     ]
    }
   ],
   "source": [
    "# Define model metadata for each model type\n",
    "model_configs = {\n",
    "    'Linear Regression': {\n",
    "        'description': 'Linear Regression baseline model for time series demand forecasting',\n",
    "        'algorithm': 'Linear Regression',\n",
    "        'framework': 'scikit-learn',\n",
    "        'content_types': ['text/csv', 'application/octet-stream'],\n",
    "        'response_types': ['text/csv']\n",
    "    },\n",
    "    'Ridge Regression': {\n",
    "        'description': 'Ridge Regression with L2 regularization for time series forecasting',\n",
    "        'algorithm': 'Ridge Regression',\n",
    "        'framework': 'scikit-learn',\n",
    "        'content_types': ['text/csv', 'application/octet-stream'],\n",
    "        'response_types': ['text/csv']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'description': 'Random Forest ensemble model with 200 trees',\n",
    "        'algorithm': 'Random Forest',\n",
    "        'framework': 'scikit-learn',\n",
    "        'content_types': ['text/csv', 'application/octet-stream'],\n",
    "        'response_types': ['text/csv']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'description': 'XGBoost gradient boosting model optimized for time series',\n",
    "        'algorithm': 'XGBoost',\n",
    "        'framework': 'XGBoost',\n",
    "        'content_types': ['text/csv', 'application/octet-stream'],\n",
    "        'response_types': ['text/csv']\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'description': 'LightGBM light gradient boosting machine model',\n",
    "        'algorithm': 'LightGBM',\n",
    "        'framework': 'LightGBM',\n",
    "        'content_types': ['text/csv', 'application/octet-stream'],\n",
    "        'response_types': ['text/csv']\n",
    "    },\n",
    "    'ETS': {\n",
    "        'description': 'Exponential Smoothing (Holt-Winters) for seasonal time series',\n",
    "        'algorithm': 'Exponential Smoothing',\n",
    "        'framework': 'statsmodels',\n",
    "        'content_types': ['text/csv'],\n",
    "        'response_types': ['text/csv']\n",
    "    },\n",
    "    'SARIMA': {\n",
    "        'description': 'SARIMA(1,1,1)(1,1,1,12) statistical model with seasonal components',\n",
    "        'algorithm': 'SARIMA',\n",
    "        'framework': 'statsmodels',\n",
    "        'content_types': ['text/csv'],\n",
    "        'response_types': ['text/csv']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get model performance data\n",
    "performance_dict = {row['Model']: row for _, row in results_df.iterrows()}\n",
    "\n",
    "# Get valid SageMaker container images for supported frameworks\n",
    "try:\n",
    "    sklearn_image = sagemaker.image_uris.retrieve('sklearn', region)\n",
    "    xgboost_image = sagemaker.image_uris.retrieve('xgboost', region)\n",
    "except Exception as e:\n",
    "    print(f\"Note: Could not retrieve SageMaker images: {e}\")\n",
    "    sklearn_image = None\n",
    "    xgboost_image = None\n",
    "\n",
    "# Create model packages\n",
    "model_package_arns = {}\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    perf_data = performance_dict.get(model_name, {})\n",
    "    \n",
    "    # Format description as single line (AWS validation regex doesn't allow newlines)\n",
    "    mae_val = f\"{perf_data.get('MAE', 0):.2f}\" if isinstance(perf_data.get('MAE'), (int, float)) else \"N/A\"\n",
    "    rmse_val = f\"{perf_data.get('RMSE', 0):.2f}\" if isinstance(perf_data.get('RMSE'), (int, float)) else \"N/A\"\n",
    "    r2_val = f\"{perf_data.get('R2', 0):.4f}\" if isinstance(perf_data.get('R2'), (int, float)) else \"N/A\"\n",
    "    mape_val = f\"{perf_data.get('MAPE', 0):.2f}\" if isinstance(perf_data.get('MAPE'), (int, float)) else \"N/A\"\n",
    "    \n",
    "    description = f\"{config['description']} | Performance: MAE={mae_val}, RMSE={rmse_val}, R2={r2_val}, MAPE={mape_val}%\"\n",
    "    \n",
    "    # Select appropriate container image based on framework\n",
    "    if config['framework'] == 'scikit-learn' and sklearn_image:\n",
    "        container_image = sklearn_image\n",
    "    elif config['framework'] == 'XGBoost' and xgboost_image:\n",
    "        container_image = xgboost_image\n",
    "    else:\n",
    "        container_image = None\n",
    "    \n",
    "    try:\n",
    "        # Build create_model_package request\n",
    "        create_pkg_args = {\n",
    "            'ModelPackageGroupName': model_package_group_name,\n",
    "            'ModelPackageDescription': description,\n",
    "            'ModelApprovalStatus': 'PendingManualApproval'\n",
    "        }\n",
    "        \n",
    "        # Only include InferenceSpecification if we have a valid image\n",
    "        if container_image:\n",
    "            create_pkg_args['InferenceSpecification'] = {\n",
    "                'Containers': [\n",
    "                    {\n",
    "                        'Image': container_image,\n",
    "                        'ModelDataUrl': model_metadata[model_name]['model_s3_path']\n",
    "                    }\n",
    "                ],\n",
    "                'SupportedContentTypes': config['content_types'],\n",
    "                'SupportedResponseMIMETypes': config['response_types']\n",
    "            }\n",
    "        \n",
    "        response = sm_client.create_model_package(**create_pkg_args)\n",
    "        model_package_arn = response['ModelPackageArn']\n",
    "        model_package_arns[model_name] = model_package_arn\n",
    "        pkg_type = \"with InferenceSpec\" if container_image else \"metadata-only\"\n",
    "        print(f\"‚úì Model Package created for {model_name} ({pkg_type})\")\n",
    "        print(f\"  ARN: {model_package_arn}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error creating package for {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f3e65",
   "metadata": {},
   "source": [
    "## Part 4: Create Model Cards with Detailed Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b41a4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model Card created for Linear Regression\n",
      "  Card Name: timeseries-fc-linear-regression-2026-02-21-21-58-00\n",
      "‚úì Model Card created for Ridge Regression\n",
      "  Card Name: timeseries-fc-ridge-regression-2026-02-21-21-58-00\n",
      "‚úì Model Card created for Random Forest\n",
      "  Card Name: timeseries-fc-random-forest-2026-02-21-21-58-00\n",
      "‚úì Model Card created for XGBoost\n",
      "  Card Name: timeseries-fc-xgboost-2026-02-21-21-58-00\n",
      "‚úì Model Card created for LightGBM\n",
      "  Card Name: timeseries-fc-lightgbm-2026-02-21-21-58-00\n",
      "‚úì Model Card created for ETS\n",
      "  Card Name: timeseries-fc-ets-2026-02-21-21-58-00\n",
      "‚úì Model Card created for SARIMA\n",
      "  Card Name: timeseries-fc-sarima-2026-02-21-21-58-00\n"
     ]
    }
   ],
   "source": [
    "timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "# Create Model Cards for each model\n",
    "for model_name, config in model_configs.items():\n",
    "    perf_data = performance_dict.get(model_name, {})\n",
    "    \n",
    "    model_card_name = f\"timeseries-fc-{model_name.replace(' ', '-').lower()}-{timestamp}\"\n",
    "    \n",
    "    # Model Card content must follow AWS SageMaker's strict schema\n",
    "    card_content = json.dumps({\n",
    "        \"model_overview\": {\n",
    "            \"model_id\": model_name,\n",
    "            \"model_name\": f\"Time Series {model_name}\",\n",
    "            \"model_owner\": \"NG Demand Forecasting Team\",\n",
    "            \"model_version\": 1,\n",
    "            \"problem_type\": \"Time Series Forecasting\",\n",
    "            \"algorithm_type\": config['algorithm']\n",
    "        },\n",
    "        \"intended_uses\": {\n",
    "            \"purpose_of_model\": \"Forecast natural gas demand for the next 12 months\",\n",
    "            \"intended_uses\": \"Production forecasting for demand planning and supply chain optimization\",\n",
    "            \"factors_affecting_model_efficiency\": \"Model performance depends on data quality, seasonal patterns, and external factors like weather.\"\n",
    "        },\n",
    "        \"business_details\": {\n",
    "            \"business_problem\": \"Accurate demand forecasting for supply chain optimization\",\n",
    "            \"business_stakeholders\": \"Operations, Supply Chain, and Finance teams\"\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        sm_client.create_model_card(\n",
    "            ModelCardName=model_card_name,\n",
    "            ModelCardStatus='Draft',\n",
    "            Content=card_content\n",
    "        )\n",
    "        print(f\"‚úì Model Card created for {model_name}\")\n",
    "        print(f\"  Card Name: {model_card_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error creating model card for {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa945e",
   "metadata": {},
   "source": [
    "## Part 5: Model Registry Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90257063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL REGISTRY SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üì¶ Model Package Group: timeseries-demand-forecasting\n",
      "üìç S3 Location: s3://sagemaker-us-east-1-681195727402/timeseries-demand-forecasting/models/\n",
      "‚è∞ Created: 2026-02-21-21-58-00\n",
      "\n",
      "üìã REGISTERED MODELS:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üèÜ BEST: ETS (Holt-Winters)\n",
      "   ARN: N/A\n",
      "   RMSE: 339,687.9 | MAPE: 2.62% | R¬≤: 0.9408\n",
      "\n",
      "  #2: SARIMA(1,1,1)(1,1,1,12)\n",
      "   ARN: N/A\n",
      "   RMSE: 441,158.3 | MAPE: 2.74% | R¬≤: 0.9001\n",
      "\n",
      "  #3: XGBoost\n",
      "   ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/4\n",
      "   RMSE: 446,809.1 | MAPE: 3.18% | R¬≤: 0.8975\n",
      "\n",
      "  #4: Random Forest\n",
      "   ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/3\n",
      "   RMSE: 478,332.2 | MAPE: 2.92% | R¬≤: 0.8825\n",
      "\n",
      "  #5: LightGBM\n",
      "   ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/5\n",
      "   RMSE: 491,168.5 | MAPE: 2.97% | R¬≤: 0.8762\n",
      "\n",
      "  #6: Ridge Regression\n",
      "   ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/2\n",
      "   RMSE: 513,663.8 | MAPE: 4.23% | R¬≤: 0.8646\n",
      "\n",
      "  #7: Linear Regression\n",
      "   ARN: arn:aws:sagemaker:us-east-1:681195727402:model-package/timeseries-demand-forecasting/1\n",
      "   RMSE: 528,703.9 | MAPE: 4.30% | R¬≤: 0.8565\n"
     ]
    }
   ],
   "source": [
    "# Create summary report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL REGISTRY SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüì¶ Model Package Group: {model_package_group_name}\")\n",
    "print(f\"üìç S3 Location: s3://{bucket}/{s3_prefix}/\")\n",
    "print(f\"‚è∞ Created: {timestamp}\")\n",
    "\n",
    "print(\"\\nüìã REGISTERED MODELS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    model_name = row['Model']\n",
    "    rank = idx + 1\n",
    "    rmse = row['RMSE']\n",
    "    mape = row['MAPE']\n",
    "    \n",
    "    status = \"üèÜ BEST\" if rank == 1 else f\"  #{rank}\"\n",
    "    \n",
    "    print(f\"\\n{status}: {model_name}\")\n",
    "    print(f\"   ARN: {model_package_arns.get(model_name, 'N/A')}\")\n",
    "    print(f\"   RMSE: {rmse:,.1f} | MAPE: {mape:.2f}% | R¬≤: {row['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9aa017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Model registry exported to model_registry.csv\n",
      "                     Model           RMSE      MAPE        R2\n",
      "0       ETS (Holt-Winters)  339687.886113  2.622832  0.940767\n",
      "1  SARIMA(1,1,1)(1,1,1,12)  441158.333879  2.739047  0.900093\n",
      "2                  XGBoost  446809.083481  3.184616  0.897517\n",
      "3            Random Forest  478332.234626  2.917507  0.882546\n",
      "4                 LightGBM  491168.478068  2.967178  0.876158\n",
      "5         Ridge Regression  513663.825094  4.234959  0.864554\n",
      "6        Linear Regression  528703.889226  4.302964  0.856507\n"
     ]
    }
   ],
   "source": [
    "# Export model registry to CSV for tracking\n",
    "registry_export = results_df.copy()\n",
    "registry_export['ARN'] = registry_export['Model'].map(model_package_arns)\n",
    "registry_export['Timestamp'] = timestamp\n",
    "registry_export['S3_Path'] = registry_export['Model'].apply(\n",
    "    lambda x: f\"s3://{bucket}/{s3_prefix}/{x.replace(' ', '_').replace('(', '').replace(')', '')}.pkl\"\n",
    ")\n",
    "\n",
    "registry_export.to_csv('model_registry.csv', index=False)\n",
    "print(\"\\n‚úì Model registry exported to model_registry.csv\")\n",
    "print(registry_export[['Model', 'RMSE', 'MAPE', 'R2']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e7e58",
   "metadata": {},
   "source": [
    "## Part 6: Approve Best Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "024abf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model's ARN\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model_arn = model_package_arns.get(best_model_name)\n",
    "\n",
    "if best_model_arn:\n",
    "    try:\n",
    "        sm_client.update_model_package(\n",
    "            ModelPackageArn=best_model_arn,\n",
    "            ModelApprovalStatus='Approved'\n",
    "        )\n",
    "        print(f\"‚úì Best Model '{best_model_name}' approved for production\")\n",
    "        print(f\"  ARN: {best_model_arn}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Could not update approval status: {e}\")\n",
    "        print(f\"  Manual approval may be required in SageMaker console\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e869ccd6",
   "metadata": {},
   "source": [
    "## Part 7: Query Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c42ac64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Querying Model Registry for: timeseries-demand-forecasting\n",
      "\n",
      "Found 7 model packages:\n",
      "\n",
      "1. 7\n",
      "   Status: Completed | Approved: PendingManualApproval\n",
      "\n",
      "2. 6\n",
      "   Status: Completed | Approved: PendingManualApproval\n",
      "\n",
      "3. 5\n",
      "   Status: Completed | Approved: PendingManualApproval\n",
      "\n",
      "4. 4\n",
      "   Status: Completed | Approved: PendingManualApproval\n",
      "\n",
      "5. 3\n",
      "   Status: Completed | Approved: PendingManualApproval\n",
      "\n",
      "6. 2\n",
      "   Status: Completed | Approved: PendingManualApproval\n",
      "\n",
      "7. 1\n",
      "   Status: Completed | Approved: PendingManualApproval\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all model packages in the group\n",
    "print(f\"\\nüìö Querying Model Registry for: {model_package_group_name}\\n\")\n",
    "\n",
    "paginator = sm_client.get_paginator('list_model_packages')\n",
    "page_iterator = paginator.paginate(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    PaginationConfig={'PageSize': 10}\n",
    ")\n",
    "\n",
    "model_package_list = []\n",
    "for page in page_iterator:\n",
    "    for package in page['ModelPackageSummaryList']:\n",
    "        # Extract package name from ARN (format: arn:aws:sagemaker:region:account:model-package/name)\n",
    "        arn = package['ModelPackageArn']\n",
    "        pkg_name = arn.split('/')[-1] if '/' in arn else arn.split(':')[-1]\n",
    "        \n",
    "        model_package_list.append({\n",
    "            'Name': pkg_name,\n",
    "            'ARN': arn,\n",
    "            'Status': package['ModelPackageStatus'],\n",
    "            'Approval Status': package.get('ModelApprovalStatus', 'Unknown'),\n",
    "            'Created': package['CreationTime']\n",
    "        })\n",
    "\n",
    "print(f\"Found {len(model_package_list)} model packages:\\n\")\n",
    "for idx, pkg in enumerate(model_package_list, 1):\n",
    "    print(f\"{idx}. {pkg['Name']}\")\n",
    "    print(f\"   Status: {pkg['Status']} | Approved: {pkg['Approval Status']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
